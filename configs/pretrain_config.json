{
  "model": {
    "vocab_size": 250027,
    "d_model": 1024,
    "encoder_layers": 12,
    "decoder_layers": 12,
    "encoder_attention_heads": 16,
    "decoder_attention_heads": 16,
    "encoder_ffn_dim": 4096,
    "decoder_ffn_dim": 4096,
    "max_position_embeddings": 1024,
    "dropout": 0.1,
    "attention_dropout": 0.1,
    "activation_dropout": 0.0
  },
  "training": {
    "batch_size": 8,
    "max_steps": 5000,
    "learning_rate": 5e-4,
    "warmup_steps": 500,
    "weight_decay": 0.01,
    "max_grad_norm": 1.0,
    "save_interval": 1000,
    "eval_interval": 500,
    "log_interval": 50
  },
  "data": {
    "max_length": 512,
    "num_samples": 10000,
    "languages": ["en_XX", "ro_RO"],
    "noise_types": ["span_masking", "sentence_permutation"],
    "mask_prob": 0.35,
    "poisson_lambda": 3.5
  },
  "output": {
    "output_dir": "checkpoints/pretrain",
    "log_dir": "logs/pretrain"
  }
}